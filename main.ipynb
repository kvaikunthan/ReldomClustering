{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0ca3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import subprocess\n",
    "from scripts.GetSummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50bb8e",
   "metadata": {},
   "source": [
    "Let's use the summary function to collect the data from all participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fccb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = []\n",
    "baseDir = 'data/participantdata'\n",
    "\n",
    "for folder in os.listdir(baseDir):\n",
    "    path = os.path.join(baseDir, folder)\n",
    "    if os.path.isdir(path):\n",
    "        try:\n",
    "            summ = summary(path).reset_index()\n",
    "            summ['participant'] = folder\n",
    "            summ = summ.set_index('participant')\n",
    "            participants.append(summ)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {folder}: {e}\")\n",
    "\n",
    "summDF = pd.concat(participants)\n",
    "summDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557a6532",
   "metadata": {},
   "source": [
    "Now, let's pivot our dataframe to get a 16D vector for each participant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ed98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = summDF.pivot_table(\n",
    "    index='participant',\n",
    "    columns=['Condition'],\n",
    "    values=['accuracy', 'RT']\n",
    ")\n",
    "\n",
    "pivot.columns = [f'{condition}_{stat}' for stat, condition in pivot.columns]\n",
    "df = pivot\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a815c0",
   "metadata": {},
   "source": [
    "Now, let's filter out participants who have average accuracies on any of the tasks less than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2428283",
   "metadata": {},
   "outputs": [],
   "source": [
    "accCols = [i for i in df.columns if i.endswith('_accuracy')]\n",
    "df = df[df[accCols].min(axis=1) >= 0.5]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f46713",
   "metadata": {},
   "source": [
    "Let's export this CSV so that we can analyze it using the NBClust package in R to determine the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fdee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/preprocessed_vectors.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941280f1",
   "metadata": {},
   "source": [
    "Then, we run our R script and get back the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b68982",
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['Rscript', 'scripts/NBClustEval.R'], check=True, stdout=subprocess.DEVNULL)\n",
    "\n",
    "with open('data/optimal_k.txt', 'r') as f:\n",
    "    optimalK = int(f.read())\n",
    "\n",
    "print(f\"Optimal number of clusters: {optimalK}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5814c54e",
   "metadata": {},
   "source": [
    "Now using that we've found the number of clusters, let's implement clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872dbe65",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = StandardScaler().fit_transform(df)\n",
    "\n",
    "kmeans = KMeans(n_clusters=optimalK, n_init='auto')\n",
    "labels = kmeans.fit_predict(scaled)\n",
    "\n",
    "clusteredDf = df.copy()\n",
    "\n",
    "clusteredDf['cluster'] = labels\n",
    "clusteredDf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6ce290",
   "metadata": {},
   "source": [
    "Exporting the clustered dataframe for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae867f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusteredDf.to_csv('data/clustered_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analogy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
